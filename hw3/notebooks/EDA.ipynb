{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df6a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install findspark pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019bebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74bde7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import last\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, coalesce, lag, lit, expr, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5640ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.0.3\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Dataset Practice\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Проверка версии Spark\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5114eacb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 items\n",
      "-rw-r--r--   1 ubuntu hadoop 2807409271 2025-04-05 13:32 data/2019-08-22.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2854479008 2025-04-05 13:44 data/2019-09-21.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2895460543 2025-04-05 13:47 data/2019-10-21.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2939120942 2025-04-05 13:47 data/2019-11-20.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995462277 2025-04-05 13:42 data/2019-12-20.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2994906767 2025-04-05 13:42 data/2020-01-19.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995431240 2025-04-05 13:30 data/2020-02-18.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995176166 2025-04-05 13:40 data/2020-03-19.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2996034632 2025-04-05 13:46 data/2020-04-18.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995666965 2025-04-05 13:43 data/2020-05-18.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2994699401 2025-04-05 13:31 data/2020-06-17.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995810010 2025-04-05 13:41 data/2020-07-17.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995995152 2025-04-05 13:46 data/2020-08-16.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995778382 2025-04-05 13:36 data/2020-09-15.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995868596 2025-04-05 13:48 data/2020-10-15.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995467533 2025-04-05 13:49 data/2020-11-14.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2994761624 2025-04-05 13:40 data/2020-12-14.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995390576 2025-04-05 13:49 data/2021-01-13.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995780517 2025-04-05 13:39 data/2021-02-12.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995191659 2025-04-05 13:37 data/2021-03-14.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 2995446495 2025-04-05 13:37 data/2021-04-13.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3029170975 2025-04-05 13:50 data/2021-05-13.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042691991 2025-04-05 13:39 data/2021-06-12.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3041980335 2025-04-05 13:35 data/2021-07-12.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042662187 2025-04-05 13:51 data/2021-08-11.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042455173 2025-04-05 13:34 data/2021-09-10.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042424238 2025-04-05 13:51 data/2021-10-10.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042358698 2025-04-05 13:45 data/2021-11-09.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042923985 2025-04-05 13:41 data/2021-12-09.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042868087 2025-04-05 13:30 data/2022-01-08.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3043148790 2025-04-05 13:38 data/2022-02-07.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3042312191 2025-04-05 13:31 data/2022-03-09.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3041973966 2025-04-05 13:48 data/2022-04-08.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3073760161 2025-04-05 13:35 data/2022-05-08.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3089378246 2025-04-05 13:32 data/2022-06-07.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3089589719 2025-04-05 13:38 data/2022-07-07.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3090000257 2025-04-05 13:34 data/2022-08-06.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3089390874 2025-04-05 13:43 data/2022-09-05.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3109468067 2025-04-05 13:44 data/2022-10-05.txt\n",
      "-rw-r--r--   1 ubuntu hadoop 3136657969 2025-04-05 13:33 data/2022-11-04.txt\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204ee3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tranaction_id | tx_datetime | customer_id | terminal_id | tx_amount | tx_time_seconds | tx_time_days | tx_fraud | tx_fraud_scenario\r\n",
      "0,2019-08-22 06:51:03,0,711,70.91,24663,0,0,0\r\n",
      "1,2019-08-22 05:10:37,0,0,90.55,18637,0,0,0\r\n",
      "2,2019-08-22 19:05:33,0,753,35.38,68733,0,0,0\r\n",
      "3,2019-08-22 07:21:33,0,0,80.41,26493,0,0,0\r\n",
      "4,2019-08-22 09:06:17,1,981,102.83,32777,0,0,0\r\n",
      "5,2019-08-22 18:41:25,3,205,34.20,67285,0,0,0\r\n",
      "6,2019-08-22 03:12:21,3,0,47.20,11541,0,0,0\r\n",
      "7,2019-08-22 22:36:40,6,809,139.39,81400,0,0,0\r\n",
      "8,2019-08-22 17:23:29,7,184,87.24,62609,0,0,0\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat data/2019-08-22.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afcc58ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-08-22.txt', '2019-09-21.txt', '2019-10-21.txt', '2019-11-20.txt', '2019-12-20.txt', '2020-01-19.txt', '2020-02-18.txt', '2020-03-19.txt', '2020-04-18.txt', '2020-05-18.txt', '2020-06-17.txt', '2020-07-17.txt', '2020-08-16.txt', '2020-09-15.txt', '2020-10-15.txt', '2020-11-14.txt', '2020-12-14.txt', '2021-01-13.txt', '2021-02-12.txt', '2021-03-14.txt', '2021-04-13.txt', '2021-05-13.txt', '2021-06-12.txt', '2021-07-12.txt', '2021-08-11.txt', '2021-09-10.txt', '2021-10-10.txt', '2021-11-09.txt', '2021-12-09.txt', '2022-01-08.txt', '2022-02-07.txt', '2022-03-09.txt', '2022-04-08.txt', '2022-05-08.txt', '2022-06-07.txt', '2022-07-07.txt', '2022-08-06.txt', '2022-09-05.txt', '2022-10-05.txt', '2022-11-04.txt']\n"
     ]
    }
   ],
   "source": [
    "hadoop_fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(\n",
    "    spark._jsc.hadoopConfiguration()\n",
    ")\n",
    "\n",
    "path = \"hdfs:/user/ubuntu/data\"\n",
    "file_statuses = hadoop_fs.listStatus(spark._jvm.org.apache.hadoop.fs.Path(path))\n",
    "file_list = [file.getPath().getName() for file in file_statuses]\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499070c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"tranaction_id\", IntegerType()),\n",
    "    StructField(\"tx_datetime\", TimestampType()),\n",
    "    StructField(\"customer_id\", IntegerType()),\n",
    "    StructField(\"terminal_id\", IntegerType()),\n",
    "    StructField(\"tx_amount\", DoubleType()),\n",
    "    StructField(\"tx_time_seconds\", IntegerType()),\n",
    "    StructField(\"tx_time_days\", IntegerType()),\n",
    "    StructField(\"tx_fraud\", IntegerType()),\n",
    "    StructField(\"tx_fraud_scenario\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"comment\", \"#\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(f\"hdfs:/user/ubuntu/data/{file_list[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdcca0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tranaction_id: integer (nullable = true)\n",
      " |-- tx_datetime: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- terminal_id: integer (nullable = true)\n",
      " |-- tx_amount: double (nullable = true)\n",
      " |-- tx_time_seconds: integer (nullable = true)\n",
      " |-- tx_time_days: integer (nullable = true)\n",
      " |-- tx_fraud: integer (nullable = true)\n",
      " |-- tx_fraud_scenario: integer (nullable = true)\n",
      "\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|tx_datetime        |customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|46988238     |2019-09-21 19:33:01|2          |660        |22.15    |2662381        |30          |0       |0                |\n",
      "|46988239     |2019-09-21 18:06:19|3          |732        |36.83    |2657179        |30          |0       |0                |\n",
      "|46988240     |2019-09-21 16:56:01|10         |663        |19.3     |2652961        |30          |0       |0                |\n",
      "|46988241     |2019-09-21 05:34:26|10         |145        |106.51   |2612066        |30          |0       |0                |\n",
      "|46988242     |2019-09-21 12:12:51|11         |337        |53.97    |2635971        |30          |0       |0                |\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354bdd5",
   "metadata": {},
   "source": [
    "### Проверка пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7356511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|            0|        103|          0|        778|        0|              0|           0|       0|                0|\n",
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.select([\n",
    "    sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in df.columns\n",
    "])\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53bf3301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Статистика пропущенных значений до обработки ===\n",
      "tranaction_id: 0 пропущенных значений (0.00%)\n",
      "tx_datetime: 103 пропущенных значений (0.00%)\n",
      "customer_id: 0 пропущенных значений (0.00%)\n",
      "terminal_id: 778 пропущенных значений (0.00%)\n",
      "tx_amount: 0 пропущенных значений (0.00%)\n",
      "tx_time_seconds: 0 пропущенных значений (0.00%)\n",
      "tx_time_days: 0 пропущенных значений (0.00%)\n",
      "tx_fraud: 0 пропущенных значений (0.00%)\n",
      "tx_fraud_scenario: 0 пропущенных значений (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Статистика пропущенных значений до обработки ===\")\n",
    "missing_stats = df.select([\n",
    "    F.sum(F.col(c).isNull().cast(\"int\")).alias(c) \n",
    "    for c in df.columns\n",
    "]).collect()[0]\n",
    "\n",
    "for col_name, null_count in zip(df.columns, missing_stats):\n",
    "    print(f\"{col_name}: {null_count} пропущенных значений ({null_count/df.count()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae38d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = Window.partitionBy(\"customer_id\").orderBy(\"tranaction_id\")\n",
    "# clean_df = df.withColumn(\"tx_datetime\", last(\"tx_datetime\", ignorenulls=True).over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4328f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_clean = clean_df.select([\n",
    "#     sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "#     for c in clean_df.columns\n",
    "# ])\n",
    "# missing_values_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "085bed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-------------------+-------------------+-------------------+------------------+\n",
      "|tranaction_id|tx_datetime        |customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|is_datetime_imputed|tx_datetime_filled |is_terminal_imputed|terminal_id_filled|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-------------------+-------------------+-------------------+------------------+\n",
      "|46988238     |2019-09-21 19:33:01|2          |660        |22.15    |2662381        |30          |0       |0                |false              |2019-09-21 19:33:01|false              |660               |\n",
      "|46988239     |2019-09-21 18:06:19|3          |732        |36.83    |2657179        |30          |0       |0                |false              |2019-09-21 18:06:19|false              |732               |\n",
      "|46988240     |2019-09-21 16:56:01|10         |663        |19.3     |2652961        |30          |0       |0                |false              |2019-09-21 16:56:01|false              |663               |\n",
      "|46988241     |2019-09-21 05:34:26|10         |145        |106.51   |2612066        |30          |0       |0                |false              |2019-09-21 05:34:26|false              |145               |\n",
      "|46988242     |2019-09-21 12:12:51|11         |337        |53.97    |2635971        |30          |0       |0                |false              |2019-09-21 12:12:51|false              |337               |\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-------------------+-------------------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy(\"tranaction_id\")\n",
    "\n",
    "# Обрабатываем пропуски\n",
    "df_clean = (df\n",
    "    # Флаг пропущенных дат\n",
    "    .withColumn(\"is_datetime_imputed\", \n",
    "                col(\"tx_datetime\").isNull())\n",
    "    \n",
    "    # Заполняем пропуски в дате: предыдущая дата + 1 секунда\n",
    "    .withColumn(\"tx_datetime\",\n",
    "                coalesce(\n",
    "                    col(\"tx_datetime\"),\n",
    "                    lag(\"tx_datetime\", 1).over(window_spec) + expr(\"INTERVAL 1 SECOND\")\n",
    "                ))\n",
    "    \n",
    "    # Флаг пропущенных terminal_id\n",
    "    .withColumn(\"is_terminal_imputed\",\n",
    "                col(\"terminal_id\").isNull())\n",
    "    \n",
    "    # Заполняем пропуски в terminal_id специальным значением\n",
    "    .withColumn(\"terminal_id\",\n",
    "                coalesce(col(\"terminal_id\"), lit(-999)))\n",
    "    \n",
    "    # Флаг пропущенных terminal_id\n",
    "    .withColumn(\"is_terminal_imputed\",\n",
    "                col(\"terminal_id\").isNull())\n",
    "    \n",
    "    # Заполняем пропуски в customer_id специальным значением\n",
    "    .withColumn(\"customer_id\",\n",
    "                coalesce(col(\"customer_id\"), lit(-999)))\n",
    "    \n",
    "    # Удаляем строки, где не удалось заполнить дату (нет предыдущего значения)\n",
    "    .filter(col(\"tx_datetime\").isNotNull())\n",
    ")\n",
    "\n",
    "df_clean.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eceef9",
   "metadata": {},
   "source": [
    "### Проверка дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62245cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено полных дубликатов: 181\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-----+\n",
      "|tranaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|count|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-----+\n",
      "|     35909184|2019-09-13 20:10:14|     927611|        298|    78.84|        1973414|          22|       1|                2|    2|\n",
      "|     34610209|2019-09-13 19:25:18|      98166|        249|     82.9|        1970718|          22|       0|                0|    2|\n",
      "|     43227844|2019-09-18 14:29:41|     599043|        150|    62.01|        2384981|          27|       0|                0|    2|\n",
      "|     15974647|2019-09-01 09:06:30|     202272|        248|     79.0|         896790|          10|       0|                0|    2|\n",
      "|     24595200|2019-09-06 08:27:15|     703127|        145|    11.33|        1326435|          15|       0|                0|    2|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = df.groupBy(df.columns).count().filter(\"count > 1\")\n",
    "\n",
    "print(f\"Найдено полных дубликатов: {duplicate_rows.count()}\")\n",
    "duplicate_rows.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a6ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = clean_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8182e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate_rows = df.groupBy(df.columns).count().filter(\"count > 1\")\n",
    "\n",
    "# print(f\"Найдено полных дубликатов: {duplicate_rows.count()}\")\n",
    "# duplicate_rows.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e04a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отрицательные суммы\n",
    "df.filter(col(\"tx_amount\") < 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a01bf499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пропуски в ID\n",
    "window = Window.orderBy(\"tranaction_id\")\n",
    "df.withColumn(\"id_diff\", col(\"tranaction_id\") - lag(\"tranaction_id\", 1).over(window)) \\\n",
    "  .filter(col(\"id_diff\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "# Проверка колонок, которые должны быть числами, но содержат текст\n",
    "df.select([count(when(col(c).cast(\"float\").isNull() & col(c).isNotNull(), c)).alias(c) \n",
    "          for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebb5c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|tranaction_id|        tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "|          328|2019-08-22 17:40:13|        226|        101|   187.29|          63613|           0|       0|                0|\n",
      "|          367|2019-08-22 14:43:37|        256|        138|   262.02|          53017|           0|       1|                3|\n",
      "|          589|2019-08-22 06:47:40|        383|        312|   186.88|          24460|           0|       0|                0|\n",
      "|          630|2019-08-22 03:19:16|        410|          0|   203.01|          11956|           0|       0|                0|\n",
      "|          911|2019-08-22 15:52:24|        577|          0|    183.8|          57144|           0|       0|                0|\n",
      "|          991|2019-08-22 15:43:41|        623|         27|   218.68|          56621|           0|       0|                0|\n",
      "|         1137|2019-08-22 18:02:48|        705|         82|   178.68|          64968|           0|       0|                0|\n",
      "|         1221|2019-08-22 13:57:50|        766|        951|   186.23|          50270|           0|       0|                0|\n",
      "|         1252|2019-08-22 08:03:00|        788|        165|   210.02|          28980|           0|       0|                0|\n",
      "|         1335|2019-08-22 14:50:34|        837|        823|   185.22|          53434|           0|       0|                0|\n",
      "|         1409|2019-08-22 04:21:57|        882|        846|   179.11|          15717|           0|       0|                0|\n",
      "|         1433|2019-08-22 16:19:41|        896|        821|    189.1|          58781|           0|       0|                0|\n",
      "|         1912|2019-08-22 16:31:27|       1210|        601|   190.05|          59487|           0|       1|                2|\n",
      "|         1965|2019-08-22 16:08:34|       1246|        637|   692.39|          58114|           0|       1|                3|\n",
      "|         1967|2019-08-22 05:39:24|       1246|        259|    715.6|          20364|           0|       1|                3|\n",
      "|         2076|2019-08-22 08:28:09|       1319|        816|   198.04|          30489|           0|       0|                0|\n",
      "|         2288|2019-08-22 13:52:55|       1475|        378|   246.19|          49975|           0|       1|                1|\n",
      "|         2428|2019-08-22 04:15:55|       1569|        882|   186.86|          15355|           0|       0|                0|\n",
      "|         2720|2019-08-22 08:48:24|       1751|        787|   187.33|          31704|           0|       0|                0|\n",
      "|         2802|2019-08-22 10:42:36|       1799|        138|   186.87|          38556|           0|       0|                0|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev\n",
    "\n",
    "stats = df.select(\n",
    "     mean(\"tx_amount\").alias(\"avg\"),\n",
    "     stddev(\"tx_amount\").alias(\"std\")\n",
    ").collect()[0]\n",
    "\n",
    "upper_bound = stats[\"avg\"] + 3*stats[\"std\"]\n",
    "df.filter(col(\"tx_amount\") > upper_bound).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd269c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------+\n",
      "|tranaction_id|tx_datetime|customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|calc_days|\n",
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------+\n",
      "|       933817|       null|     597125|        611|    62.83|          86400|           0|       0|                0|        1|\n",
      "|      1164488|       null|     743659|          0|     7.25|          86400|           0|       0|                0|        1|\n",
      "|      1205236|       null|     769896|         44|     15.1|          86400|           0|       0|                0|        1|\n",
      "|      1543099|       null|     985197|        967|    85.18|          86400|           0|       0|                0|        1|\n",
      "|      1670385|       null|      66533|        956|    21.39|         172800|           1|       0|                0|        2|\n",
      "|      1781446|       null|     137885|        124|     13.7|         172800|           1|       0|                0|        2|\n",
      "|      2615257|       null|     669953|        489|    40.75|         172800|           1|       0|                0|        2|\n",
      "|      2898079|       null|     850307|        532|    14.26|         172800|           1|       0|                0|        2|\n",
      "|      3036595|       null|     938860|        481|    13.52|         172800|           1|       0|                0|        2|\n",
      "|      3837780|       null|     450941|        847|    40.38|         259200|           2|       0|                0|        3|\n",
      "|      3854919|       null|     461823|          0|    58.44|         259200|           2|       0|                0|        3|\n",
      "|      4576892|       null|     922295|        241|    59.82|         259200|           2|       0|                0|        3|\n",
      "|      5045996|       null|     221856|        600|    83.95|         345600|           3|       0|                0|        4|\n",
      "|      5263382|       null|     360203|        907|   118.27|         345600|           3|       0|                0|        4|\n",
      "|      5363822|       null|     424141|        227|    16.36|         345600|           3|       0|                0|        4|\n",
      "|      5658834|       null|     612666|        879|   124.16|         345600|           3|       0|                0|        4|\n",
      "|      5742934|       null|     666379|        223|    93.55|         345600|           3|       0|                0|        4|\n",
      "|      6986915|       null|     460833|          0|     75.3|         432000|           4|       0|                0|        5|\n",
      "|      7114613|       null|     542697|        507|    31.73|         432000|           4|       0|                0|        5|\n",
      "|      7308521|       null|     666454|        422|    21.44|         432000|           4|       0|                0|        5|\n",
      "+-------------+-----------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"calc_days\", (col(\"tx_time_seconds\")/86400).cast(\"int\")) \\\n",
    "  .filter(col(\"calc_days\") != col(\"tx_time_days\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d01a767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"customer_id\") == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07bb322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2041671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(col(\"terminal_id\") == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчет границ через IQR\n",
    "q1, q3 = df.approxQuantile(\"tx_amount\", [0.25, 0.75], 0.01)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5*iqr\n",
    "upper_bound = q3 + 1.5*iqr\n",
    "\n",
    "# Замена выбросов на граничные значения\n",
    "df_clean = df.withColumn(\n",
    "    \"tx_amount\",\n",
    "    when(col(\"tx_amount\") < lower_bound, lower_bound)\n",
    "    .when(col(\"tx_amount\") > upper_bound, upper_bound)\n",
    "    .otherwise(col(\"tx_amount\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c3370a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------------+\n",
      "|tranaction_id|tx_datetime        |customer_id|terminal_id|tx_amount|tx_time_seconds|tx_time_days|tx_fraud|tx_fraud_scenario|tx_amount_clean|\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------------+\n",
      "|46988238     |2019-09-21 19:33:01|2          |660        |22.15    |2662381        |30          |0       |0                |22.15          |\n",
      "|46988239     |2019-09-21 18:06:19|3          |732        |36.83    |2657179        |30          |0       |0                |36.83          |\n",
      "|46988240     |2019-09-21 16:56:01|10         |663        |19.3     |2652961        |30          |0       |0                |19.3           |\n",
      "|46988241     |2019-09-21 05:34:26|10         |145        |106.51   |2612066        |30          |0       |0                |106.51         |\n",
      "|46988242     |2019-09-21 12:12:51|11         |337        |53.97    |2635971        |30          |0       |0                |53.97          |\n",
      "+-------------+-------------------+-----------+-----------+---------+---------------+------------+--------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
